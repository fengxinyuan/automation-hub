"""Linux.do è®ºå›é€‚é…å™¨"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.base_adapter import BaseAdapter, CheckinResult
from modules.forum.linuxdo.ai_analyzer import AIAnalyzer
import asyncio
from typing import List, Dict, Any, Optional
import os
import json
import hashlib
from datetime import datetime, timedelta


class TopicCache:
    """å¸–å­ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, cache_file: str, cache_days: int = 7):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.cache_file = Path(cache_file)
        self.cache_days = cache_days
        self.cache: Dict[str, Dict[str, Any]] = {}
        self._load_cache()

    def _load_cache(self):
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                self._clean_expired()
            except Exception:
                self.cache = {}

    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            self.cache_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def _clean_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        expiry_time = datetime.now() - timedelta(days=self.cache_days)
        expired_keys = [
            key for key, value in self.cache.items()
            if datetime.fromisoformat(value.get('cached_at', '2000-01-01')) < expiry_time
        ]
        for key in expired_keys:
            del self.cache[key]

    def get_topic_id(self, topic: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¸–å­å”¯ä¸€æ ‡è¯†"""
        link = topic.get('link', '')
        return hashlib.md5(link.encode()).hexdigest()

    def get(self, topic: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„å¸–å­åˆ†æç»“æœ"""
        topic_id = self.get_topic_id(topic)
        return self.cache.get(topic_id)

    def set(self, topic: Dict[str, Any], analysis: Dict[str, Any]):
        """ç¼“å­˜å¸–å­åˆ†æç»“æœ"""
        topic_id = self.get_topic_id(topic)
        self.cache[topic_id] = {
            'topic': topic,
            'analysis': analysis,
            'cached_at': datetime.now().isoformat()
        }
        self._save_cache()

    def is_cached(self, topic: Dict[str, Any]) -> bool:
        """æ£€æŸ¥å¸–å­æ˜¯å¦å·²ç¼“å­˜"""
        return self.get_topic_id(topic) in self.cache


class LinuxDoAdapter(BaseAdapter):
    """Linux.do è®ºå›é€‚é…å™¨

    Linux.do æ˜¯åŸºäº Discourse çš„è®ºå›ç³»ç»Ÿ
    æ”¯æŒè‡ªåŠ¨ç™»å½•ã€è·å–æœ€æ–°å¸–å­å’Œçƒ­é—¨è¯é¢˜
    """

    # é¡µé¢åŠ è½½è¶…æ—¶é…ç½®ï¼ˆæ¯«ç§’ï¼‰
    PAGE_LOAD_TIMEOUT = 60000
    ELEMENT_WAIT_TIMEOUT = 10000

    def __init__(
        self,
        site_url: str,
        username: str,
        password: str,
        logger=None,
        # å†…å®¹è·å–é…ç½®
        latest_limit: int = 20,
        hot_limit: int = 10,
        read_limit: int = 5,
        ai_limit: int = 3,
        enable_scroll_loading: bool = False,
        scroll_times: int = 3,
        scroll_interval: float = 2.0,
        fetch_priority_categories: bool = False,
        # è¿‡æ»¤é…ç½®
        exclude_categories: Optional[List[str]] = None,
        exclude_keywords: Optional[List[str]] = None,
        priority_categories: Optional[List[str]] = None,
        min_replies: int = 0,
        min_views: int = 50,
        min_score_for_zero_replies: int = 50,
        # AI é…ç½®
        ai_enabled: bool = True,
        ai_api_key: Optional[str] = None,
        ai_api_base: Optional[str] = None,
        ai_model: str = "qwen-flash",
        ai_temperature: float = 0.7,
        ai_max_tokens: int = 800,
        user_interests: Optional[List[str]] = None
    ):
        """
        åˆå§‹åŒ– Linux.do é€‚é…å™¨

        Args:
            site_url: ç«™ç‚¹ URL
            username: ç”¨æˆ·å
            password: å¯†ç 
            logger: æ—¥å¿—è®°å½•å™¨
            latest_limit: è·å–æœ€æ–°å¸–å­æ•°é‡
            hot_limit: è·å–çƒ­é—¨å¸–å­æ•°é‡
            read_limit: æ·±åº¦é˜…è¯»å¸–å­æ•°é‡
            ai_limit: AI åˆ†æå¸–å­æ•°é‡
            enable_scroll_loading: æ˜¯å¦å¯ç”¨æ»šåŠ¨åŠ è½½
            scroll_times: æ»šåŠ¨æ¬¡æ•°
            scroll_interval: æ»šåŠ¨é—´éš”ï¼ˆç§’ï¼‰
            fetch_priority_categories: æ˜¯å¦è·å–ä¼˜å…ˆåˆ†ç±»çš„å¸–å­
            exclude_categories: æ’é™¤çš„åˆ†ç±»åˆ—è¡¨
            exclude_keywords: æ’é™¤çš„å…³é”®è¯åˆ—è¡¨
            priority_categories: ä¼˜å…ˆåˆ†ç±»åˆ—è¡¨
            min_replies: æœ€å°å›å¤æ•°
            min_views: æœ€å°æµè§ˆæ•°
            min_score_for_zero_replies: 0å›å¤å¸–å­çš„æœ€å°æµè§ˆæ•°
            ai_enabled: æ˜¯å¦å¯ç”¨ AI åŠŸèƒ½
            ai_api_key: AI API å¯†é’¥
            ai_api_base: AI API ç«¯ç‚¹
            ai_model: AI æ¨¡å‹åç§°
            ai_temperature: AI æ¸©åº¦å‚æ•°
            ai_max_tokens: AI æœ€å¤§ç”Ÿæˆé•¿åº¦
            user_interests: ç”¨æˆ·å…´è¶£åˆ—è¡¨
        """
        super().__init__(
            site_name="linuxdo",
            site_url=site_url,
            username=username,
            password=password,
            logger=logger
        )

        # ä¿å­˜å†…å®¹è·å–é…ç½®
        self.latest_limit = latest_limit
        self.hot_limit = hot_limit
        self.read_limit = read_limit
        self.ai_limit = ai_limit
        self.enable_scroll_loading = enable_scroll_loading
        self.scroll_times = scroll_times
        self.scroll_interval = scroll_interval
        self.fetch_priority_categories = fetch_priority_categories
        self.user_interests = user_interests

        # ä¿å­˜è¿‡æ»¤é…ç½®ï¼ˆä½¿ç”¨é»˜è®¤å€¼å¦‚æœæœªæä¾›ï¼‰
        self.exclude_categories = set(exclude_categories or [
            'å…¬å‘Š', 'è¿è¥åé¦ˆ', 'ç«™åŠ¡', 'Announcement', 'Feedback'
        ])
        self.exclude_keywords = exclude_keywords or [
            'ç¤¾åŒºå…¬çº¦', 'æŠ½å¥–è§„åˆ™', 'å›­ä¸é‚€è¯·', 'é˜»æ–­', 'æˆ¾æ°”',
            'ç¤¾åŒºè§„åˆ™', 'è®ºå›å…¬å‘Š', 'ç®¡ç†å‘˜', 'ç‰ˆè§„', 'å°ç¦',
            'äººè®¾è´´', 'æ°´è´´', 'çŒæ°´'
        ]
        self.priority_categories = set(priority_categories or [
            'å¼€å‘è°ƒä¼˜', 'Linux', 'æœåŠ¡å™¨ç®¡ç†', 'è‡ªåŠ¨åŒ–è¿ç»´',
            'å·¥å…·åˆ†äº«', 'æ•™ç¨‹', 'æŠ€æœ¯è®¨è®º', 'ç¼–ç¨‹', 'AI',
            'äº‘è®¡ç®—', 'Docker', 'DevOps'
        ])
        self.min_replies = min_replies
        self.min_views = min_views
        self.min_score_for_zero_replies = min_score_for_zero_replies

        # åˆå§‹åŒ– AI åˆ†æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if ai_enabled:
            # å¤„ç†ç¯å¢ƒå˜é‡
            if ai_api_key and ai_api_key.startswith('${') and ai_api_key.endswith('}'):
                env_var = ai_api_key[2:-1]
                ai_api_key = os.getenv(env_var, '')

            self.ai_analyzer = AIAnalyzer(
                api_key=ai_api_key,
                api_base=ai_api_base,
                model=ai_model,
                temperature=ai_temperature,
                max_tokens=ai_max_tokens,
                logger=logger
            )
        else:
            # åˆ›å»ºä¸€ä¸ªç¦ç”¨çš„ AI åˆ†æå™¨
            self.ai_analyzer = AIAnalyzer(api_key=None, logger=logger)

        # åˆå§‹åŒ–ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        cache_dir = PROJECT_ROOT / 'storage' / 'cache'
        cache_file = cache_dir / f'linuxdo_{username}_topics.json'
        self.cache = TopicCache(str(cache_file), cache_days=7)

    def _calculate_topic_score(self, topic: Dict[str, Any]) -> float:
        """
        è®¡ç®—å¸–å­çš„ç»¼åˆè¯„åˆ†

        è¯„åˆ†ç»´åº¦ï¼š
        1. åŸºç¡€çƒ­åº¦ï¼šå›å¤æ•° + æµè§ˆæ•°
        2. äº’åŠ¨ç‡ï¼šå›å¤æ•°/æµè§ˆæ•°æ¯”ä¾‹
        3. ä¼˜å…ˆåˆ†ç±»åŠ æˆ
        4. ç”¨æˆ·å…´è¶£åŒ¹é…åº¦
        5. æ—¶æ•ˆæ€§ï¼ˆå¦‚æœæœ‰æ—¶é—´ä¿¡æ¯ï¼‰

        Args:
            topic: å¸–å­ä¿¡æ¯

        Returns:
            ç»¼åˆè¯„åˆ†ï¼ˆ0-100ï¼‰
        """
        try:
            # è§£ææ•°å€¼ï¼ˆå¤„ç† k/ä¸‡ç­‰å•ä½ï¼‰
            def parse_number(value):
                if not value:
                    return 0
                s = str(value).lower()
                # å¤„ç† k åç¼€ï¼ˆ1k = 1000ï¼‰
                if 'k' in s:
                    s = s.replace('k', '').replace('.', '')
                    return int(float(s) * 100) if '.' in str(value) else int(s) * 1000
                # å¤„ç†ä¸‡åç¼€
                if 'ä¸‡' in s:
                    return int(float(s.replace('ä¸‡', '')) * 10000)
                # å¤„ç†å°æ•°ç‚¹ï¼ˆ3.5k -> 3500ï¼‰
                try:
                    return int(float(s))
                except:
                    return 0

            replies = parse_number(topic.get('replies', 0))
            views = parse_number(topic.get('views', 0))
            category = topic.get('category', '')
            title = topic.get('title', '')

            # 1. åŸºç¡€çƒ­åº¦åˆ† (0-40åˆ†)
            # ä½¿ç”¨å¯¹æ•°ç¼©æ”¾é¿å…å¤§æ•°å­—ä¸»å¯¼
            import math
            heat_score = min(40, (math.log10(replies + 1) * 10 + math.log10(views + 1) * 3))

            # 2. äº’åŠ¨ç‡åˆ† (0-20åˆ†)
            # é«˜äº’åŠ¨ç‡è¯´æ˜å†…å®¹æœ‰ä»·å€¼
            interaction_rate = replies / max(views, 1) * 100
            interaction_score = min(20, interaction_rate * 100)

            # 3. ä¼˜å…ˆåˆ†ç±»åŠ æˆ (0-20åˆ†)
            category_score = 0
            if category in self.priority_categories:
                category_score = 20
            elif any(pri_cat in category or pri_cat.lower() in title.lower()
                    for pri_cat in self.priority_categories):
                category_score = 10

            # 4. ç”¨æˆ·å…´è¶£åŒ¹é…åº¦ (0-20åˆ†)
            interest_score = 0
            if self.user_interests:
                # æ£€æŸ¥æ ‡é¢˜å’Œåˆ†ç±»æ˜¯å¦åŒ…å«ç”¨æˆ·å…´è¶£å…³é”®è¯
                content_text = f"{title} {category}".lower()
                matches = sum(1 for interest in self.user_interests
                            if interest.lower() in content_text)
                interest_score = min(20, matches * 10)

            # æ€»åˆ†
            total_score = heat_score + interaction_score + category_score + interest_score

            # å­˜å‚¨è¯„åˆ†ä¿¡æ¯ç”¨äºè°ƒè¯•
            topic['_score_details'] = {
                'heat': round(heat_score, 2),
                'interaction': round(interaction_score, 2),
                'category': category_score,
                'interest': interest_score,
                'total': round(total_score, 2)
            }

            return total_score

        except Exception as e:
            self.logger.debug(f"è®¡ç®—è¯„åˆ†å¤±è´¥: {str(e)}")
            return 0

    def _filter_quality_topics(self, topics: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤ä¼˜è´¨å†…å®¹ï¼Œç§»é™¤ç«™åŠ¡ã€å…¬å‘Šç­‰æ— å…³å†…å®¹

        ä½¿ç”¨é…ç½®çš„è¿‡æ»¤è§„åˆ™å’Œæ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ

        Args:
            topics: å¸–å­åˆ—è¡¨

        Returns:
            è¿‡æ»¤å¹¶æ’åºåçš„å¸–å­åˆ—è¡¨
        """
        filtered_topics = []

        for topic in topics:
            title = topic.get('title', '')
            category = topic.get('category', '')

            # è¿‡æ»¤ï¼šæ’é™¤ç‰¹å®šåˆ†ç±»
            if category in self.exclude_categories:
                self.logger.debug(f"è¿‡æ»¤åˆ†ç±» '{category}': {title[:30]}")
                continue

            # è¿‡æ»¤ï¼šæ’é™¤åŒ…å«ç‰¹å®šå…³é”®è¯çš„å¸–å­
            if any(keyword in title for keyword in self.exclude_keywords):
                self.logger.debug(f"è¿‡æ»¤å…³é”®è¯: {title[:30]}")
                continue

            # è¿‡æ»¤ï¼šæ’é™¤ä½è´¨é‡å¸–å­
            try:
                def parse_number(value):
                    if not value:
                        return 0
                    s = str(value).lower()
                    if 'k' in s:
                        s = s.replace('k', '').replace('.', '')
                        return int(float(s) * 100) if '.' in str(value) else int(s) * 1000
                    try:
                        return int(float(s))
                    except:
                        return 0

                replies = parse_number(topic.get('replies', '0'))
                views = parse_number(topic.get('views', '0'))

                # 0å›å¤çš„å¸–å­éœ€è¦æ›´é«˜çš„æµè§ˆæ•°
                if replies == 0 and views < self.min_score_for_zero_replies:
                    self.logger.debug(f"è¿‡æ»¤ä½è´¨é‡ï¼ˆ0å›å¤ï¼Œä½æµè§ˆï¼‰: {title[:30]}")
                    continue

                # æ™®é€šè´¨é‡è¿‡æ»¤
                if replies < self.min_replies and views < self.min_views:
                    self.logger.debug(f"è¿‡æ»¤ä½è´¨é‡: {title[:30]}")
                    continue

            except Exception as e:
                self.logger.debug(f"è§£ææ•°å€¼å¤±è´¥: {str(e)}")
                pass

            # è®¡ç®—ç»¼åˆè¯„åˆ†
            score = self._calculate_topic_score(topic)
            topic['quality_score'] = score

            # æ·»åŠ ä¼˜å…ˆçº§æ ‡è®°ï¼ˆå‘åå…¼å®¹ï¼‰
            topic['is_priority'] = category in self.priority_categories or any(
                cat in category or cat.lower() in title.lower()
                for cat in self.priority_categories
            )

            filtered_topics.append(topic)

        # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰
        filtered_topics.sort(key=lambda t: t.get('quality_score', 0), reverse=True)

        self.logger.info(
            f"å†…å®¹è¿‡æ»¤: {len(topics)} -> {len(filtered_topics)} ä¸ªå¸–å­ "
            f"(å¹³å‡è¯„åˆ†: {sum(t.get('quality_score', 0) for t in filtered_topics) / max(len(filtered_topics), 1):.1f})"
        )

        return filtered_topics

    async def checkin(self) -> CheckinResult:
        """
        æ‰§è¡Œç­¾åˆ°æ“ä½œ

        ä¼˜åŒ–æ–¹æ¡ˆï¼š
        - ä¸²è¡Œè·å–å¸–å­åˆ—è¡¨ï¼ˆé¿å…è§¦å‘é™åˆ¶ï¼‰
        - å¹¶å‘è¯»å–å†…å®¹å’Œ AI åˆ†æï¼ˆæé€Ÿï¼‰
        - ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤åˆ†æ
        """
        try:
            # ä¸²è¡Œè·å–å¸–å­åˆ—è¡¨
            self.logger.info(f"è·å–å¸–å­åˆ—è¡¨...")
            latest_topics_raw = await self.get_latest_topics(limit=self.latest_limit)
            await asyncio.sleep(0.3)  # å‡å°‘è¯·æ±‚é—´éš”

            hot_topics_raw = await self.get_hot_topics(limit=self.hot_limit)
            await asyncio.sleep(0.3)

            # å¦‚æœå¯ç”¨äº†ä¼˜å…ˆåˆ†ç±»è·å–
            category_topics_raw = []
            if self.fetch_priority_categories and self.priority_categories:
                self.logger.info(f"è·å–ä¼˜å…ˆåˆ†ç±»å¸–å­...")
                for category in list(self.priority_categories)[:2]:
                    try:
                        topics = await self.get_category_topics(category, limit=15)
                        category_topics_raw.extend(topics)
                        await asyncio.sleep(0.3)
                    except Exception as e:
                        self.logger.debug(f"åˆ†ç±» '{category}' è·å–å¤±è´¥: {str(e)}")

            # åº”ç”¨å†…å®¹è¿‡æ»¤
            latest_topics = self._filter_quality_topics(latest_topics_raw)
            hot_topics = self._filter_quality_topics(hot_topics_raw)
            category_topics = self._filter_quality_topics(category_topics_raw) if category_topics_raw else []

            # åˆå¹¶å¹¶å»é‡
            all_topics_raw = latest_topics + hot_topics + category_topics
            seen = set()
            all_topics = []
            for t in all_topics_raw:
                if t['link'] not in seen:
                    seen.add(t['link'])
                    all_topics.append(t)

            # æŒ‰è¯„åˆ†æ’åº
            all_topics.sort(key=lambda t: t.get('quality_score', 0), reverse=True)
            self.logger.info(f"å»é‡åå…± {len(all_topics)} ä¸ªå¸–å­")

            # å¹¶å‘è¯»å–å¸–å­å†…å®¹ï¼ˆé™æµé¿å…è§¦å‘åçˆ¬ï¼‰
            self.logger.info(f"è¯»å–å¸–å­å†…å®¹ï¼ˆ{self.read_limit} æ¡ï¼‰...")
            read_count = min(self.read_limit, len(all_topics))
            semaphore = asyncio.Semaphore(3)  # æœ€å¤š3ä¸ªå¹¶å‘

            async def fetch_with_limit(topic):
                async with semaphore:
                    await asyncio.sleep(0.3)  # å‡å°‘å»¶è¿Ÿ
                    return await self.get_topic_content(topic['link'])

            # ä½¿ç”¨ asyncio.gather å¹¶å‘è·å–
            content_tasks = [fetch_with_limit(topic) for topic in all_topics[:read_count]]
            contents = await asyncio.gather(*content_tasks, return_exceptions=True)

            # å¤„ç†ç»“æœ
            topics_with_content = []
            for topic, content in zip(all_topics[:read_count], contents):
                if isinstance(content, Exception):
                    self.logger.debug(f"å†…å®¹è·å–å¤±è´¥: {topic['title'][:30]}")
                    continue
                if content and content.get('first_post', '').strip():
                    topic_with_content = topic.copy()
                    topic_with_content['content_summary'] = content
                    topics_with_content.append(topic_with_content)

            self.logger.info(f"æˆåŠŸè¯»å– {len(topics_with_content)} ä¸ªå¸–å­å†…å®¹")

            # å°†å¸¦å†…å®¹çš„å¸–å­æ›´æ–°å› all_topicsï¼ˆé€šè¿‡é“¾æ¥åŒ¹é…ï¼‰
            content_map = {t['link']: t for t in topics_with_content}
            for i, topic in enumerate(all_topics):
                if topic['link'] in content_map:
                    all_topics[i] = content_map[topic['link']]

            # åŒæ—¶æ›´æ–° latest_topics å’Œ hot_topics ä¸­çš„å†…å®¹
            for i, topic in enumerate(latest_topics):
                if topic['link'] in content_map:
                    latest_topics[i] = content_map[topic['link']]
            for i, topic in enumerate(hot_topics):
                if topic['link'] in content_map:
                    hot_topics[i] = content_map[topic['link']]

            # ç¼“å­˜+å¹¶å‘AIåˆ†æ
            self.logger.info(f"AI åˆ†æï¼ˆ{self.ai_limit} ä¸ªå¸–å­ï¼‰...")
            ai_summaries = []
            cached_count = 0

            # åˆ†ç¦»ç¼“å­˜å’Œéœ€è¦åˆ†æçš„å¸–å­
            to_analyze = []
            for topic in topics_with_content[:self.ai_limit]:
                cached_data = self.cache.get(topic)
                if cached_data:
                    topic['ai_summary'] = cached_data.get('analysis', {})
                    ai_summaries.append(topic)
                    cached_count += 1
                else:
                    content_text = topic.get('content_summary', {}).get('first_post', '')
                    if content_text and len(content_text) > 100:
                        to_analyze.append(topic)

            # å¹¶å‘åˆ†ææœªç¼“å­˜çš„å¸–å­
            if to_analyze:
                self.logger.info(f"åˆ†æ {len(to_analyze)} ä¸ªæ–°å¸–å­ï¼ˆ{cached_count} ä¸ªä½¿ç”¨ç¼“å­˜ï¼‰")
                analysis_tasks = [
                    self.ai_analyzer.summarize_topic(
                        topic,
                        topic.get('content_summary', {}).get('first_post', '')
                    )
                    for topic in to_analyze
                ]
                ai_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)

                for topic, ai_result in zip(to_analyze, ai_results):
                    if not isinstance(ai_result, Exception):
                        topic['ai_summary'] = ai_result
                        ai_summaries.append(topic)
                        self.cache.set(topic, ai_result)

                self.logger.info(f"AIåˆ†æå®Œæˆ: {len(ai_summaries)} ä¸ª")
            elif cached_count > 0:
                self.logger.info(f"å…¨éƒ¨ä½¿ç”¨ç¼“å­˜: {cached_count} ä¸ªå¸–å­")

            # ä½¿ç”¨ AI ç”Ÿæˆæ¨èåˆ—è¡¨
            self.logger.info("ç”Ÿæˆæ¨èåˆ—è¡¨...")
            user_profile = {'interests': self.user_interests} if self.user_interests else None
            recommended_topics = await self.ai_analyzer.analyze_interests(
                topics=all_topics,
                user_profile=user_profile
            )

            # ç”Ÿæˆæ‘˜è¦
            summary = self._generate_summary(
                latest_topics,
                hot_topics,
                ai_summaries,
                recommended_topics
            )

            return CheckinResult(
                True,
                f"æˆåŠŸè·å–è®ºå›åŠ¨æ€å¹¶ç”Ÿæˆ AI åˆ†æï¼ˆå…±{len(all_topics)}ä¸ªå¸–å­ï¼Œæ¨è{len(recommended_topics[:10])}ä¸ªï¼‰",
                {
                    "latest_topics": latest_topics,
                    "hot_topics": hot_topics,
                    "category_topics": category_topics,
                    "topics_with_content": topics_with_content,
                    "ai_summaries": ai_summaries,
                    "recommended_topics": recommended_topics[:10],  # åªä¿ç•™å‰10ä¸ªæ¨è
                    "summary": summary
                }
            )

        except Exception as e:
            self.logger.error(f"è·å–å¸–å­ä¿¡æ¯å‡ºé”™: {str(e)}")
            await self.take_screenshot("checkin_exception")
            return CheckinResult(False, f"è·å–å¸–å­ä¿¡æ¯å‡ºé”™: {str(e)}")

    async def get_latest_topics(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æœ€æ–°å¸–å­åˆ—è¡¨ï¼ˆæ”¯æŒæ»šåŠ¨åŠ è½½ï¼‰

        Args:
            limit: è·å–æ•°é‡é™åˆ¶

        Returns:
            å¸–å­åˆ—è¡¨
        """
        try:
            # è®¿é—®æœ€æ–°é¡µé¢
            latest_url = f"{self.site_url}/latest"
            await self.page.goto(latest_url, wait_until='domcontentloaded', timeout=self.PAGE_LOAD_TIMEOUT)
            await asyncio.sleep(2)

            # å¦‚æœå¯ç”¨äº†æ»šåŠ¨åŠ è½½ï¼Œæ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
            if self.enable_scroll_loading:
                self.logger.debug(f"å¼€å§‹æ»šåŠ¨åŠ è½½æ›´å¤šå¸–å­ï¼ˆ{self.scroll_times}æ¬¡ï¼‰...")
                for i in range(self.scroll_times):
                    # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                    await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    await asyncio.sleep(self.scroll_interval)

                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ–°å†…å®¹
                    current_count = await self.page.evaluate(
                        "document.querySelectorAll('.topic-list-item, [data-topic-id]').length"
                    )
                    self.logger.debug(f"  æ»šåŠ¨ {i+1}/{self.scroll_times}ï¼Œå½“å‰å¸–å­æ•°ï¼š{current_count}")

                    # å¦‚æœå·²ç»è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œå¯ä»¥æå‰é€€å‡º
                    if current_count >= limit:
                        self.logger.debug(f"  å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {limit}ï¼Œåœæ­¢æ»šåŠ¨")
                        break

            await self.take_screenshot("latest_topics")

            # ä½¿ç”¨ JavaScript æå–å¸–å­ä¿¡æ¯
            topics = await self.page.evaluate(f"""
                (limit) => {{
                    const topics = [];
                    const topicElements = document.querySelectorAll('.topic-list-item, [data-topic-id]');

                    topicElements.forEach((el, idx) => {{
                        if (idx >= limit) return;

                        // æ ‡é¢˜å’Œé“¾æ¥
                        const titleEl = el.querySelector('.title a, .topic-title a, a.title');
                        const title = titleEl ? titleEl.textContent.trim() : '';
                        const link = titleEl ? titleEl.getAttribute('href') : '';

                        // ä½œè€…
                        const authorEl = el.querySelector('.topic-poster a, .author a');
                        const author = authorEl ? authorEl.getAttribute('data-user-card') || authorEl.textContent.trim() : '';

                        // å›å¤æ•°å’Œæµè§ˆæ•°
                        const repliesEl = el.querySelector('.posts, .num.posts');
                        const replies = repliesEl ? repliesEl.textContent.trim() : '0';

                        const viewsEl = el.querySelector('.views, .num.views');
                        const views = viewsEl ? viewsEl.textContent.trim() : '0';

                        // æœ€åæ´»åŠ¨æ—¶é—´
                        const activityEl = el.querySelector('.age.activity a, time');
                        const lastActivity = activityEl ? activityEl.getAttribute('title') || activityEl.textContent.trim() : '';

                        // åˆ†ç±»
                        const categoryEl = el.querySelector('.category, .badge-category');
                        const category = categoryEl ? categoryEl.textContent.trim() : '';

                        if (title && link) {{
                            topics.push({{
                                title,
                                link,
                                author,
                                replies,
                                views,
                                lastActivity,
                                category
                            }});
                        }}
                    }});

                    return topics;
                }}
            """, limit)

            self.logger.info(f"è·å–åˆ° {len(topics)} ä¸ªæœ€æ–°å¸–å­")
            return topics

        except Exception as e:
            self.logger.error(f"è·å–æœ€æ–°å¸–å­å¤±è´¥: {str(e)}")
            return []

    async def get_hot_topics(self, limit: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–çƒ­é—¨å¸–å­åˆ—è¡¨ï¼ˆæ”¯æŒæ»šåŠ¨åŠ è½½ï¼‰

        Args:
            limit: è·å–æ•°é‡é™åˆ¶

        Returns:
            å¸–å­åˆ—è¡¨
        """
        try:
            # è®¿é—®çƒ­é—¨é¡µé¢
            hot_url = f"{self.site_url}/top"
            await self.page.goto(hot_url, wait_until='domcontentloaded', timeout=self.PAGE_LOAD_TIMEOUT)
            await asyncio.sleep(2)

            # å¦‚æœå¯ç”¨äº†æ»šåŠ¨åŠ è½½ï¼Œæ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
            if self.enable_scroll_loading:
                self.logger.debug(f"å¼€å§‹æ»šåŠ¨åŠ è½½æ›´å¤šçƒ­é—¨å¸–å­ï¼ˆ{self.scroll_times}æ¬¡ï¼‰...")
                for i in range(self.scroll_times):
                    await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    await asyncio.sleep(self.scroll_interval)

                    current_count = await self.page.evaluate(
                        "document.querySelectorAll('.topic-list-item, [data-topic-id]').length"
                    )
                    self.logger.debug(f"  æ»šåŠ¨ {i+1}/{self.scroll_times}ï¼Œå½“å‰å¸–å­æ•°ï¼š{current_count}")

                    if current_count >= limit:
                        self.logger.debug(f"  å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {limit}ï¼Œåœæ­¢æ»šåŠ¨")
                        break

            await self.take_screenshot("hot_topics")

            # ä½¿ç”¨ä¸ get_latest_topics ç›¸åŒçš„æå–é€»è¾‘
            topics = await self.page.evaluate(f"""
                (limit) => {{
                    const topics = [];
                    const topicElements = document.querySelectorAll('.topic-list-item, [data-topic-id]');

                    topicElements.forEach((el, idx) => {{
                        if (idx >= limit) return;

                        const titleEl = el.querySelector('.title a, .topic-title a, a.title');
                        const title = titleEl ? titleEl.textContent.trim() : '';
                        const link = titleEl ? titleEl.getAttribute('href') : '';

                        const authorEl = el.querySelector('.topic-poster a, .author a');
                        const author = authorEl ? authorEl.getAttribute('data-user-card') || authorEl.textContent.trim() : '';

                        const repliesEl = el.querySelector('.posts, .num.posts');
                        const replies = repliesEl ? repliesEl.textContent.trim() : '0';

                        const viewsEl = el.querySelector('.views, .num.views');
                        const views = viewsEl ? viewsEl.textContent.trim() : '0';

                        const activityEl = el.querySelector('.age.activity a, time');
                        const lastActivity = activityEl ? activityEl.getAttribute('title') || activityEl.textContent.trim() : '';

                        const categoryEl = el.querySelector('.category, .badge-category');
                        const category = categoryEl ? categoryEl.textContent.trim() : '';

                        if (title && link) {{
                            topics.push({{
                                title,
                                link,
                                author,
                                replies,
                                views,
                                lastActivity,
                                category
                            }});
                        }}
                    }});

                    return topics;
                }}
            """, limit)

            self.logger.info(f"è·å–åˆ° {len(topics)} ä¸ªçƒ­é—¨å¸–å­")
            return topics

        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨å¸–å­å¤±è´¥: {str(e)}")
            return []

    async def get_category_topics(self, category_name: str, limit: int = 20) -> List[Dict[str, Any]]:
        """
        ä»ç‰¹å®šåˆ†ç±»è·å–å¸–å­

        Args:
            category_name: åˆ†ç±»åç§°ï¼ˆå¦‚"ç¦åˆ©ç¾Šæ¯›"ï¼‰
            limit: è·å–æ•°é‡é™åˆ¶

        Returns:
            å¸–å­åˆ—è¡¨
        """
        try:
            # æ ¹æ®åˆ†ç±»åç§°æ„å»º URLï¼ˆDiscourse çš„åˆ†ç±» URL æ ¼å¼ï¼‰
            # Linux.do çš„åˆ†ç±» URL æ ¼å¼: https://linux.do/c/{category-slug}/{id}
            # éœ€è¦å…ˆæ˜ å°„åˆ†ç±»åç§°åˆ° slug
            category_map = {
                'ç¦åˆ©ç¾Šæ¯›': 'welfare',
                'ä¼˜æƒ æ´»åŠ¨': 'promotion',
                'å·¥å…·åˆ†äº«': 'tools',
                'å¼€å‘è°ƒä¼˜': 'dev',
                'èµ„æºèŸèƒ': 'resources'
            }

            category_slug = category_map.get(category_name, category_name.lower())

            # å°è¯•é€šè¿‡æœç´¢æ‰¾åˆ°åˆ†ç±»
            # æˆ–è€…ç›´æ¥è®¿é—®åˆ†ç±»é¡µé¢ï¼ˆå¦‚æœçŸ¥é“IDï¼‰
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æœç´¢åŠŸèƒ½æ¥æ‰¾åˆ°åˆ†ç±»å¸–å­
            search_url = f"{self.site_url}/latest?category={category_slug}"

            self.logger.debug(f"è®¿é—®åˆ†ç±»é¡µé¢: {search_url}")
            await self.page.goto(search_url, wait_until='domcontentloaded', timeout=self.PAGE_LOAD_TIMEOUT)
            await asyncio.sleep(2)

            # æ»šåŠ¨åŠ è½½æ›´å¤š
            if self.enable_scroll_loading:
                self.logger.debug(f"åœ¨åˆ†ç±» '{category_name}' ä¸­æ»šåŠ¨åŠ è½½...")
                for i in range(self.scroll_times):
                    await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    await asyncio.sleep(self.scroll_interval)

            # æå–å¸–å­
            topics = await self.page.evaluate(f"""
                (limit) => {{
                    const topics = [];
                    const topicElements = document.querySelectorAll('.topic-list-item, [data-topic-id]');

                    topicElements.forEach((el, idx) => {{
                        if (idx >= limit) return;

                        const titleEl = el.querySelector('.title a, .topic-title a, a.title');
                        const title = titleEl ? titleEl.textContent.trim() : '';
                        const link = titleEl ? titleEl.getAttribute('href') : '';

                        const authorEl = el.querySelector('.topic-poster a, .author a');
                        const author = authorEl ? authorEl.getAttribute('data-user-card') || authorEl.textContent.trim() : '';

                        const repliesEl = el.querySelector('.posts, .num.posts');
                        const replies = repliesEl ? repliesEl.textContent.trim() : '0';

                        const viewsEl = el.querySelector('.views, .num.views');
                        const views = viewsEl ? viewsEl.textContent.trim() : '0';

                        const activityEl = el.querySelector('.age.activity a, time');
                        const lastActivity = activityEl ? activityEl.getAttribute('title') || activityEl.textContent.trim() : '';

                        const categoryEl = el.querySelector('.category, .badge-category');
                        const category = categoryEl ? categoryEl.textContent.trim() : '';

                        if (title && link) {{
                            topics.push({{
                                title,
                                link,
                                author,
                                replies,
                                views,
                                lastActivity,
                                category
                            }});
                        }}
                    }});

                    return topics;
                }}
            """, limit)

            self.logger.info(f"ä»åˆ†ç±» '{category_name}' è·å–åˆ° {len(topics)} ä¸ªå¸–å­")
            return topics

        except Exception as e:
            self.logger.error(f"ä»åˆ†ç±» '{category_name}' è·å–å¸–å­å¤±è´¥: {str(e)}")
            return []

    async def get_topic_content(self, topic_link: str, max_retries: int = 2) -> Dict[str, str]:
        """
        è·å–å¸–å­è¯¦ç»†å†…å®¹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            topic_link: å¸–å­é“¾æ¥ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            å¸–å­å†…å®¹æ‘˜è¦å­—å…¸ï¼ŒåŒ…å«ï¼š
            - first_post: ç¬¬ä¸€æ¥¼å†…å®¹ï¼ˆæˆªå–å‰500å­—ç¬¦ï¼‰
            - key_points: å…³é”®ä¿¡æ¯ç‚¹åˆ—è¡¨
        """
        topic_url = f"{self.site_url}{topic_link}"

        for attempt in range(max_retries + 1):
            try:
                # è®¿é—®å¸–å­é¡µé¢
                self.logger.debug(f"è®¿é—®å¸–å­: {topic_url} (å°è¯• {attempt + 1}/{max_retries + 1})")

                # ä½¿ç”¨ networkidle ç­‰å¾…ç­–ç•¥ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
                await self.page.goto(
                    topic_url,
                    wait_until='domcontentloaded',
                    timeout=self.PAGE_LOAD_TIMEOUT
                )

                # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿é¡µé¢ç¨³å®š
                await asyncio.sleep(3)

                # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿäº†é‡å®šå‘
                current_url = self.page.url
                if topic_url not in current_url and topic_link not in current_url:
                    self.logger.debug(f"æ£€æµ‹åˆ°é‡å®šå‘: {topic_url} -> {current_url}")
                    # å¦‚æœé‡å®šå‘äº†ï¼Œå†ç­‰å¾…ä¸€ä¸‹
                    await asyncio.sleep(2)

                # æå–å¸–å­å†…å®¹
                content_data = await self.page.evaluate("""
                    () => {
                        // è·å–ç¬¬ä¸€æ¥¼å†…å®¹
                        const firstPost = document.querySelector('.topic-post:first-of-type .cooked, article.post:first-of-type .cooked');
                        let firstPostText = '';

                        if (firstPost) {
                            // ç§»é™¤ä»£ç å—å’Œå¼•ç”¨å—ï¼Œåªä¿ç•™ä¸»è¦æ–‡æœ¬
                            const clone = firstPost.cloneNode(true);

                            // ç§»é™¤ä»£ç å—
                            clone.querySelectorAll('pre, code').forEach(el => el.remove());

                            // ç§»é™¤å¼•ç”¨
                            clone.querySelectorAll('blockquote').forEach(el => el.remove());

                            // ç§»é™¤å›¾ç‰‡
                            clone.querySelectorAll('img').forEach(el => el.remove());

                            firstPostText = clone.textContent.trim();

                            // æˆªå–å‰800å­—ç¬¦
                            if (firstPostText.length > 800) {
                                firstPostText = firstPostText.substring(0, 800) + '...';
                            }
                        }

                        // å°è¯•æå–å…³é”®ä¿¡æ¯ï¼ˆåˆ—è¡¨é¡¹ã€åŠ ç²—æ–‡æœ¬ç­‰ï¼‰
                        const keyPoints = [];
                        if (firstPost) {
                            // æå–åˆ—è¡¨é¡¹
                            const listItems = firstPost.querySelectorAll('li');
                            listItems.forEach((item, idx) => {
                                if (idx < 3) {  // åªå–å‰3ä¸ª
                                    const text = item.textContent.trim();
                                    if (text.length < 100 && text.length > 10) {
                                        keyPoints.push(text);
                                    }
                                }
                            });

                            // å¦‚æœæ²¡æœ‰åˆ—è¡¨é¡¹ï¼Œæå–åŠ ç²—æ–‡æœ¬
                            if (keyPoints.length === 0) {
                                const boldTexts = firstPost.querySelectorAll('strong, b');
                                boldTexts.forEach((item, idx) => {
                                    if (idx < 3) {
                                        const text = item.textContent.trim();
                                        if (text.length < 100 && text.length > 5) {
                                            keyPoints.push(text);
                                        }
                                    }
                                });
                            }
                        }

                        return {
                            first_post: firstPostText,
                            key_points: keyPoints
                        };
                    }
                """)

                # éªŒè¯å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if content_data.get('first_post', '').strip():
                    self.logger.debug(f"æˆåŠŸæå–å†…å®¹: {len(content_data.get('first_post', ''))} å­—ç¬¦")
                    return content_data
                else:
                    # å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æ˜¯é¡µé¢æœªåŠ è½½å®Œæˆ
                    if attempt < max_retries:
                        self.logger.debug(f"å†…å®¹ä¸ºç©ºï¼Œç­‰å¾…åé‡è¯•...")
                        await asyncio.sleep(3)
                        continue
                    else:
                        self.logger.debug(f"å†…å®¹ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                        return {"first_post": "", "key_points": []}

            except Exception as e:
                if attempt < max_retries:
                    self.logger.debug(f"è·å–å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {str(e)[:100]}, ç­‰å¾…åé‡è¯•...")
                    await asyncio.sleep(3)  # é‡è¯•å‰ç­‰å¾…
                else:
                    self.logger.debug(f"è·å–å¸–å­å†…å®¹å¤±è´¥: {str(e)[:100]}")
                    return {"first_post": "", "key_points": []}

        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ˆå®‰å…¨è¿”å›ï¼‰
        return {"first_post": "", "key_points": []}

    def _generate_summary(
        self,
        latest_topics: List[Dict[str, Any]],
        hot_topics: List[Dict[str, Any]],
        ai_summaries: List[Dict[str, Any]] = None,
        recommended_topics: List[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆè®ºå›åŠ¨æ€æ‘˜è¦

        Args:
            latest_topics: æœ€æ–°å¸–å­åˆ—è¡¨
            hot_topics: çƒ­é—¨å¸–å­åˆ—è¡¨
            ai_summaries: AI åˆ†æçš„å¸–å­åˆ—è¡¨
            recommended_topics: æ¨èå¸–å­åˆ—è¡¨

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        summary_lines = []

        summary_lines.append("=" * 60)
        summary_lines.append("Linux.do è®ºå›æ™ºèƒ½åˆ†ææŠ¥å‘Š")
        summary_lines.append("=" * 60)

        # ===== AI æ¨èçš„æœ€æ„Ÿå…´è¶£çš„è¯é¢˜ =====
        if recommended_topics and len(recommended_topics) > 0:
            summary_lines.append("\nã€ğŸ¯ ä¸ºä½ æ¨è - æœ€å¯èƒ½æ„Ÿå…´è¶£çš„è¯é¢˜ã€‘")
            for i, topic in enumerate(recommended_topics[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
                score = topic.get('relevance_score', 0)
                reason = topic.get('recommendation_reason', 'çƒ­é—¨è¯é¢˜')
                tags = topic.get('recommendation_tags', [])

                summary_lines.append(
                    f"\n{i}. {topic['title']}"
                )
                summary_lines.append(
                    f"   ğŸ“Š ç›¸å…³åº¦: {score}% | ğŸ’¬ {topic['replies']} | ğŸ‘ï¸ {topic['views']}"
                )
                summary_lines.append(
                    f"   ğŸ“ æ¨èç†ç”±: {reason}"
                )
                if tags:
                    summary_lines.append(
                        f"   ğŸ·ï¸ æ ‡ç­¾: {', '.join(tags)}"
                    )
                summary_lines.append(
                    f"   ğŸ”— {self.site_url}{topic['link']}"
                )

        # ===== AI æ·±åº¦åˆ†æçš„å¸–å­ =====
        if ai_summaries and len(ai_summaries) > 0:
            summary_lines.append("\nã€ğŸ¤– AI æ·±åº¦åˆ†æã€‘")
            for i, topic in enumerate(ai_summaries, 1):
                ai_summary = topic.get('ai_summary', {})

                summary_lines.append(f"\n{i}. {topic['title']}")
                summary_lines.append(f"   ä½œè€…: {topic['author']} | åˆ†ç±»: {topic['category']}")

                # AI ç”Ÿæˆçš„æ‘˜è¦
                if ai_summary.get('summary'):
                    summary_lines.append(f"   ğŸ“ AI æ‘˜è¦: {ai_summary['summary']}")

                # å…³é”®ç‚¹
                if ai_summary.get('key_points'):
                    summary_lines.append("   ğŸ”‘ å…³é”®è¦ç‚¹:")
                    for point in ai_summary['key_points'][:3]:
                        summary_lines.append(f"      â€¢ {point}")

                # æ ‡ç­¾
                if ai_summary.get('tags'):
                    summary_lines.append(f"   ğŸ·ï¸ ä¸»é¢˜æ ‡ç­¾: {', '.join(ai_summary['tags'])}")

                # æƒ…æ„Ÿ
                sentiment_emoji = {"positive": "ğŸ˜Š", "negative": "ğŸ˜Ÿ", "neutral": "ğŸ˜"}
                sentiment = ai_summary.get('sentiment', 'neutral')
                summary_lines.append(f"   ğŸ’­ æƒ…æ„Ÿå€¾å‘: {sentiment_emoji.get(sentiment, 'ğŸ˜')} {sentiment}")

                summary_lines.append(f"   ğŸ”— {self.site_url}{topic['link']}")

        # ===== æœ€æ–°å¸–å­ =====
        if latest_topics:
            summary_lines.append("\nã€ğŸ“° æœ€æ–°å¸–å­ã€‘")
            for i, topic in enumerate(latest_topics[:10], 1):
                summary_lines.append(
                    f"{i}. {topic['title']}\n"
                    f"   ä½œè€…: {topic['author']} | "
                    f"åˆ†ç±»: {topic['category']} | "
                    f"å›å¤: {topic['replies']} | "
                    f"æµè§ˆ: {topic['views']}\n"
                    f"   é“¾æ¥: {self.site_url}{topic['link']}"
                )

        # ===== çƒ­é—¨å¸–å­ =====
        if hot_topics:
            summary_lines.append("\nã€ğŸ”¥ çƒ­é—¨è¯é¢˜ã€‘")
            for i, topic in enumerate(hot_topics[:10], 1):
                summary_lines.append(
                    f"{i}. {topic['title']}\n"
                    f"   ä½œè€…: {topic['author']} | "
                    f"åˆ†ç±»: {topic['category']} | "
                    f"å›å¤: {topic['replies']} | "
                    f"æµè§ˆ: {topic['views']}\n"
                    f"   é“¾æ¥: {self.site_url}{topic['link']}"
                )

        summary_lines.append("\n" + "=" * 60)
        summary_lines.append(f"ğŸ“Š ç»Ÿè®¡: å…±åˆ†æ {len(latest_topics) + len(hot_topics)} ä¸ªå¸–å­")
        if recommended_topics:
            summary_lines.append(f"ğŸ¯ ä¸ºä½ æ¨è {min(5, len(recommended_topics))} ä¸ªæœ€ç›¸å…³è¯é¢˜")
        if ai_summaries:
            summary_lines.append(f"ğŸ¤– AI æ·±åº¦åˆ†æ {len(ai_summaries)} ä¸ªçƒ­é—¨å¸–å­")
        summary_lines.append("=" * 60)

        return "\n".join(summary_lines)
